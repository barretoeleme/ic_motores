\documentclass{article}

% Pacotes
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{float}
\usepackage{enumitem}
\usepackage[style=abnt, backend=biber]{biblatex}
\usepackage{csquotes}
\addbibresource{referencias.bib} % Arquivo .bib com referências

% Configurações de página
\geometry{a4paper, top=3cm, bottom=3cm, left=3cm, right=2.5cm}
\setlength{\parindent}{1.25cm}
\setlength{\parskip}{0.1cm}

% Início do documento
\begin{document}

% Capa
\begin{titlepage}
    \centering
    \vspace*{3cm}
    {\Large\textbf{UFOP - Universidade Federal de Ouro Preto}} \\ 
    [0.3cm]
    {\large Decom - Departamento de Ciência da Computação} \\ 
    [3cm]
    {\huge\bfseries Modelos Básicos para IPMSMs} \\ 
    [1.5cm]
    {\large Autor: Bianca Barreto Leme} \\ 
    [0.5cm]
    {\large Matrícula: 24.1.4008} \\ 
    [0.5cm]
    {\large Professor: Rodrigo César Pedrosa Silva} \\ 
    [4cm]
    {\large Ouro Preto - MG} \\
    {\large \today}
\end{titlepage}

% Sumário
\tableofcontents
\newpage

% Introdução
\section{Introdução}

% Por enquanto, estou só fazendo um resumo sobre os tópicos pra me guiar um pouco sobre o que devo falar e detalhar depois.

% O que são IPMSMs
Os Motores Síncronos de Ímã Interno Permanente (IPMSMs) têm sido amplamente utilizados por serem uma alternativa menos agressiva ao meio ambiente, quando comparados aos motores de carros comuns.

% Por quê usar aprendizado de máquina para a análise de IPMSMs?
Em fase de testes (Finite Element Analysis), os motores devem ser submetidos a várias condições de velocidade e torque. Fazer estes testes fisicamente é custoso e pode levar dias. Por essa razão, utilizar ``motores virtuais'' e prever suas perdas através de modelos de IA pode ser muito mais viável, pois este método não tem grandes custos e levam por volta de algumas horas.

% Por quê é importante estudar IPMSMs?
Estudando IPMSMs podemos criar modelos de inteligência artificial que nos auxiliem a predizer as principais causas de perdas em ferro de determinado motor: perda por histerese e perda por eddy current.

% Objetivo do trabalho: Encontrar o melhor modelo possível para a predição de loss das IPMSMs analisadas.
Nesse contexto, este estudo tem como objetivo principal encontrar o melhor modelo de IA possível para predizer as perdas em histerese e eddy current de 3 motores IPMSMs analisados: 2D, Nabla e V.

% Metodologia
\section{Fundamentos}

% Descreva os métodos, algoritmos ou procedimentos utilizados. Pode incluir diagramas, equações ou pseudocódigo.

Nesta seção do trabalho, serão descritos os métodos, algoritmos, procedimentos e métricas utilizadas para atingir o objetivo.



\subsection{Bases de dados}

As bases de dados consistem em estados de cada parâmetro dos motores em diferentes condições, e se dividem em duas partes: a primeira destinada para o treinamento dos modelos (train) e a segunda para a testagem de suas acurácias (test).

Destes datasets, os parâmetros se categorizam em outros dois grupos: Features (X) \--- variáveis preditoras ou independentes \--- e Targets (y) \--- variáveis alvo ou dependentes.

\begin{itemize}
    \item Features:
    \begin{itemize}
        \item Variáveis geométricas (Xgeom);
        \item Velocidade do motor (N);
        \item Corrente no eixo direto (Id);
        \item Corrente no eixo em quadratura (Iq);
    \end{itemize}
    \item Targets:
    \begin{itemize}
        \item Perda por histerese (hysteresis);
        \item Perda por eddy current (joule).    
    \end{itemize}
\end{itemize}

\noindent Em resumo, a base de dados se separa em 4:

\begin{itemize}
    \item X train: features para treino;
    \item y train: targets para treino;
    \item X test: features para teste;
    \item y test: targets para teste.
\end{itemize}

\noindent Esses termos serão utilizados ao longo do artigo para melhor comunicação.


\newpage


\subsection{Motores analisados}

\noindent Neste trabalho, foram analisados 3 IPMSMs distintos:

\begin{itemize}
    \item 2D
    \\
        \begin{figure}[htbp]
            \centering
            \includegraphics[width=0.5\textwidth]{images/diagram_2d.png}
            \caption{Diagrama do motor 2D.}
            \label{fig:diagram_2d}
        \end{figure}
    \item Nabla
    \\
        \begin{figure}[htbp]
            \centering
            \includegraphics[width=0.5\textwidth]{images/diagram_nabla.png}
            \caption{Diagrama do motor Nabla.}
            \label{fig:diagram_nabla}
        \end{figure}
    \item V
    \\
        \begin{figure}[htbp]
            \centering
            \includegraphics[width=0.5\textwidth]{images/diagram_v.png}
            \caption{Diagrama do motor V.}
            \label{fig:diagram_v}
        \end{figure}
\end{itemize}


\newpage


\subsection{Métricas de Avaliação de Modelos de Regressão}

Para a análise da eficácia de cada modelo na predição dos atributos, foram definidas três métricas\dots

\subsubsection{Mean Absolute Percentage Error (MAPE)}

O \textit{Mean Absolute Percentage Error} (MAPE) mede o erro percentual médio entre
os valores reais $y_i$ e os valores previstos $\hat{y}_i$:

\[
MAPE = \frac{100\%}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|
\]



\subsubsection{Mean Squared Error (MSE)}

O \textit{Mean Squared Error} (MSE) mede o erro quadrático médio, penalizando mais
fortemente desvios grandes:

\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]



\subsubsection{Coeficiente de Determinação ($R^2$)}

O coeficiente de determinação, ou $R^2$, mede a proporção da variância dos dados
reais que é explicada pelo modelo:

\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\]

onde $\bar{y}$ é a média dos valores reais.


\newpage
% ----------------------------



\subsection{Modelos Utilizados}

Nesta seção, serão apresentados os diferentes modelos de aprendizado de máquina utilizados para a predição. 



\subsubsection{Regressão Linear}

A regressão linear busca modelar a relação entre variáveis de entrada $x_1, x_2, \dots, x_p$ e uma variável de saída $y$, assumindo que essa relação é aproximadamente linear. O modelo é definido por:
\[
\hat{y} = \beta_0 + \sum_{i=1}^p \beta_i x_i,
\]
onde $\beta_0$ é o intercepto e os coeficientes $\beta_i$ representam o peso de cada variável preditora.  

Os parâmetros $\boldsymbol{\beta}$ são estimados pelo método dos mínimos quadrados ordinários (MQO), que minimiza o erro quadrático médio:
\[
\hat{\boldsymbol{\beta}} = \arg \min_{\boldsymbol{\beta}} \sum_{j=1}^n \left(y_j - \beta_0 - \sum_{i=1}^p \beta_i x_{ij}\right)^2.
\]



\subsubsection{Regression Trees}

Uma árvore de regressão divide o espaço das variáveis preditoras em regiões disjuntas $R_1, R_2, \dots, R_M$.  
O modelo pode ser escrito como:
\[
\hat{y}(x) = \sum_{m=1}^M c_m \cdot \mathbb{1}(x \in R_m),
\]
onde $\mathbb{1}(\cdot)$ é a função indicadora, que vale 1 se $x$ pertence à região $R_m$ e 0 caso contrário.  
O valor $c_m$ é geralmente a média dos valores de saída $y$ dos pontos de treino naquela região.



\subsubsection{Random Forests}

O modelo de Random Forests combina $B$ árvores de regressão, cada uma construída a partir de amostras bootstrap dos dados de treino e subconjuntos aleatórios das variáveis. A previsão é a média das árvores:
\[
\hat{y}(x) = \frac{1}{B} \sum_{b=1}^B T_b(x),
\]
onde $T_b(x)$ representa a previsão da $b$-ésima árvore.  



\subsubsection{XGBoost}

O XGBoost é baseado em \textit{gradient boosting}, que combina árvores de forma aditiva para corrigir erros sucessivos. O modelo após $K$ iterações é:
\[
\hat{y}^{(K)}(x) = \sum_{k=1}^K f_k(x), \quad f_k \in \mathcal{F},
\]
onde cada $f_k$ é uma árvore de regressão e $\mathcal{F}$ é o espaço de funções possíveis.  

A cada passo, adiciona-se uma nova árvore $f_k(x)$ para minimizar uma função de perda regularizada:
\[
\mathcal{L}^{(K)} = \sum_{j=1}^n l\big(y_j, \hat{y}^{(K-1)}(x_j) + f_K(x_j)\big) + \Omega(f_K),
\]
onde $l(\cdot)$ é a função de perda (ex.: erro quadrático) e $\Omega(f)$ controla a complexidade do modelo.



\subsubsection{CatBoost}

O CatBoost também segue o princípio do \textit{gradient boosting}, mas introduz técnicas específicas para lidar com variáveis categóricas e reduzir o viés preditivo. Sua formulação geral é semelhante ao XGBoost:
\[
\hat{y}^{(K)}(x) = \sum_{k=1}^K f_k(x),
\]
mas a diferença está no processo de construção das árvores $f_k(x)$, que utiliza estratégias de ordenação para codificação de variáveis categóricas e um esquema de regularização que evita o sobreajuste.


\newpage
% ----------------------


\section{Metodologia}

Para atingir os objetivos deste trabalho, foram definidos 2 experimentos\dots

\subsection{Experimento 1: Identificar os Modelos mais Promissores}

Para esta primeira fase, os hiperparâmetros utilizados foram os já estabelecidos pela linguagem Python, sem nenhuma alteração feita pela pesquisa.

Os modelos de aprendizado foram alimentados com as bases de dados destinadas para treino, X train e y train. Os modelos com target em hysteresis e os com target em joule foram treinados separadamente.

Após essa fase, os dados de X test são fornecidos aos modelos já treinados que fornecem, então, os resultados preditos \--- y pred. A acurácia dos modelos é avaliada pela semelhança entre os valores reais em y test e os valores preditos em y pred. Essa acurácia é refletida nas métricas MSE, MAPE e R² score.

Esse processo foi executado com todos os modelos descritos na seção 2.4.

\subsection{Experimento 2: Identificar o melhor conjunto de hiper parâmetros para os modelos mais promissores}

Após o primeiro experimento, foi observado que os dois modelos mais promissores para predição de perdas são XGBoost e CatBoost.

% Resultados
\section{Resultados}
% Apresente os resultados obtidos (tabelas, gráficos, análises). Interprete os dados de forma clara e objetiva.

\subsection{Resultados em MAPE}
\subsection{Resultados em MAPE}
\subsection{Resultados em R² Score}


% Conclusão
\section{Conclusão}
Retome os objetivos e destaque os principais achados. Comente limitações e sugestões para trabalhos futuros.

% Referências
\newpage
% \printbibliography

\end{document}
