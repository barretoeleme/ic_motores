{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bdd9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4f9834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOTOR = \"Nabla\"\n",
    "PATH = f\"../dataset/{MOTOR}/\"\n",
    "TRAIN_FILE = \"_all_scaled_train.csv\"\n",
    "TEST_FILE = \"_all_scaled_test.csv\"\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "\n",
    "train_data = pd.concat([train_data, pd.read_csv(f'{PATH}idiq{TRAIN_FILE}').drop(columns = \"Unnamed: 0\")], axis = 1)\n",
    "train_data['speed'] = pd.read_csv(f'{PATH}speed{TRAIN_FILE}')['N']\n",
    "train_data = pd.concat([train_data, pd.read_csv(f'{PATH}xgeom{TRAIN_FILE}').drop(columns = \"Unnamed: 0\")], axis = 1)\n",
    "train_data['hysteresis'] = pd.read_csv(f'{PATH}hysteresis{TRAIN_FILE}')['total']\n",
    "train_data['joule'] = pd.read_csv(f'{PATH}joule{TRAIN_FILE}')['total']\n",
    "\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "test_data = pd.concat([test_data, pd.read_csv(f'{PATH}idiq{TEST_FILE}').drop(columns = \"Unnamed: 0\")], axis = 1)\n",
    "test_data['speed'] = pd.read_csv(f'{PATH}speed{TEST_FILE}')['N']\n",
    "test_data = pd.concat([test_data, pd.read_csv(f'{PATH}xgeom{TEST_FILE}').drop(columns = \"Unnamed: 0\")], axis = 1)\n",
    "test_data['hysteresis'] = pd.read_csv(f'{PATH}hysteresis{TEST_FILE}')['total']\n",
    "test_data['joule'] = pd.read_csv(f'{PATH}joule{TEST_FILE}')['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c3c7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, features_dim, num_out, neurons = 5, layers = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "        \n",
    "        modules.append(nn.Linear(features_dim, neurons))\n",
    "        modules.append(nn.ReLU())\n",
    "        for i in range(layers):\n",
    "            modules.append(nn.Linear(neurons, neurons))\n",
    "            modules.append(nn.ReLU())\n",
    "        modules.append(nn.Linear(neurons, num_out))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        modules.append(nn.Linear(num_out, neurons))\n",
    "        modules.append(nn.ReLU())\n",
    "        for i in range(layers):\n",
    "            modules.append(nn.Linear(neurons, neurons))\n",
    "            modules.append(nn.ReLU())\n",
    "        modules.append(nn.Linear(neurons, features_dim))\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encode(x)\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72edf6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotorDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08ccd99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_csv(contents, info, MOTOR):\n",
    "    new_row = pd.DataFrame([contents], columns = info.columns)\n",
    "    info = pd.concat([info, new_row])\n",
    "    info.to_csv(f'./data/motor_{MOTOR}_info.csv')\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "987455cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['hysteresis', 'joule']\n",
    "\n",
    "train_dataset = MotorDataset(train_data.drop(columns = target), train_data[target])\n",
    "test_dataset = MotorDataset(test_data.drop(columns = target), test_data[target])\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "columns = ['neurons', 'layers', 'learn_rate', 'epochs', 'hys_score', 'hys_mse', 'hys_mape', 'jou_score', 'jou_mse', 'jou_mape', 'time']\n",
    "info = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "150f8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = np.arange(1, 20 + 1, 1)\n",
    "layers = [1, 2]\n",
    "learning_rates = [0.1, 0.01]\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7a0e1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=14, out_features=5, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=5, out_features=2, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=5, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Autoencoder(14, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb36fa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model --- 1-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 1-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 1-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 1-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 2-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 2-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 2-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 2-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 3-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 3-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 3-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 3-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 4-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 4-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 4-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 4-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 5-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 5-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 5-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 5-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 6-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 6-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 6-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 6-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 7-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 7-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 7-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 7-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 8-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 8-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 8-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 8-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 9-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 9-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 9-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 9-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 10-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 10-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 10-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 10-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 11-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 11-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 11-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 11-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 12-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 12-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 12-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 12-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 13-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 13-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 13-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 13-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 14-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 14-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 14-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 14-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 15-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 15-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 15-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 15-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 16-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 16-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 16-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 16-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 17-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 17-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 17-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 17-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 18-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 18-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 18-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 18-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 19-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 19-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 19-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 19-2-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 20-1-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 20-1-0.01-10\n",
      "\n",
      "\n",
      "Training model --- 20-2-0.1-10\n",
      "\n",
      "\n",
      "Training model --- 20-2-0.01-10\n",
      "\n",
      "\tFinished training model at 2025-11-26 15:47:44.809807.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(neurons)):\n",
    "    for j in range(len(layers)):\n",
    "        for k in range(len(learning_rates)):\n",
    "            print(f\"\\nTraining model --- {neurons[i]}-{layers[j]}-{learning_rates[k]}-{epochs}\\n\")\n",
    "\n",
    "            features_dim = len(train_data.columns.drop(target))\n",
    "            out_dim = 20\n",
    "            model = Autoencoder(features_dim, out_dim, neurons[i], layers[j])\n",
    "\n",
    "            loss_func = nn.MSELoss()\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr = learning_rates[k])\n",
    "\n",
    "            for a in range(epochs):\n",
    "                model.train()\n",
    "                for X, y in train_loader:\n",
    "                    pred_train = model(X)\n",
    "                    loss = loss_func(pred_train, X)\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "time = datetime.datetime.now()\n",
    "print(f\"\\tFinished training model at {time}.\\n\")\n",
    "\n",
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        pred_test = model(X)\n",
    "        y_pred_list.append(pred_test)\n",
    "        y_test_list.append(y)\n",
    "\n",
    "y_pred = torch.cat(y_pred_list)\n",
    "y_test = torch.cat(y_test_list)\n",
    "\n",
    "hys_score = r2_score(y_test[:, 0], y_pred[:, 0])\n",
    "hys_mse = mean_squared_error(y_test[:, 0], y_pred[:, 0])\n",
    "hys_mape = mean_absolute_percentage_error(y_test[:, 0], y_pred[:, 0])\n",
    "\n",
    "jou_score = r2_score(y_test[:, 1], y_pred[:, 1])\n",
    "jou_mse = mean_squared_error(y_test[:, 1], y_pred[:, 1])\n",
    "jou_mape = mean_absolute_percentage_error(y_test[:, 1], y_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59adde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim =\n",
    "\n",
    "autoencoder_model = Autoencoder(input_dim, latent_dim)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "autoencoder_model.to(device)\n",
    "\n",
    "print(autoencoder_model)\n",
    "\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    autoencoder_model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for data, _ in train_loader: # _ is the target, which is same as data\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder_model(data)\n",
    "        loss = criterion(outputs, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    autoencoder_model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader: # _ is the target, which is same as data\n",
    "            data = data.to(device)\n",
    "            outputs = autoencoder_model(data)\n",
    "            loss = criterion(outputs, data)\n",
    "            running_val_loss += loss.item() * data.size(0)\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(test_loader.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
